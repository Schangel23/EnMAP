{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1478b0a3-8ce1-435f-a64d-745dbeab8091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing collection: ENMAP_HSI_L2A\n",
      "==================================================\n",
      "\n",
      "Searching for ENMAP_HSI_L2A data...\n",
      "Found 7 items.\n",
      "\n",
      "Filtering by cloud cover...\n",
      "After cloud cover filtering (5.0% max): 2 items\n",
      "Will download 2 items.\n",
      "\n",
      "Using existing directory at: EnMAP_downloads/L2A\n",
      "\n",
      "Processing item 1/2\n",
      "Cloud cover: 2%\n",
      "Item properties:\n",
      "  version: 01.04.02\n",
      "  created: 2024-07-05T11:16:53.923+00:00\n",
      "  updated: 2024-07-05T11:16:53.923+00:00\n",
      "  datetime: 2024-06-26T11:11:39Z\n",
      "  start_datetime: 2024-06-26T11:11:39.641792Z\n",
      "  end_datetime: 2024-06-26T11:11:44.176515Z\n",
      "  platform: enmap\n",
      "  proj:epsg: None\n",
      "  sat:relative_orbit: 12040\n",
      "  sat:orbit_state: DESCENDING\n",
      "  eo:cloud_cover: 2\n",
      "  eo:snow_cover: 0\n",
      "  view:sun_azimuth: 348.49244999999996\n",
      "  view:sun_elevation: 62.246176\n",
      "  processing:facility: NZ\n",
      "  processing:level: L2A\n",
      "  eop:sensorType: OPTICAL\n",
      "  card4l:eastern_geometric_accuracy: 6.0\n",
      "  card4l:geometric_accuracy_radial_rmse: 10.0\n",
      "  card4l:northern_geometric_accuracy: 8.0\n",
      "  card4l:specification: SR\n",
      "  card4l:specification_version: 5.0\n",
      "  enmap:SWIRAorSWIRBSelected: SWIRA\n",
      "  enmap:acquisitionConfiguration: earth\n",
      "  enmap:acquisitionType: EARTH\n",
      "  enmap:acrossOffNadirAngle: -0.807831354459\n",
      "  enmap:alongOffNadirAngle: -0.238772573323\n",
      "  enmap:archivedVersion: 01.04.02\n",
      "  enmap:biomeType: Temperate Broadleaf and Mixed Forests\n",
      "  enmap:cirrus_cover: 0\n",
      "  enmap:cloud_shadow: 1\n",
      "  enmap:compressionType: COMPRESSED\n",
      "  enmap:datatakeID: 0000079715\n",
      "  enmap:defectivePixelsSWIR: 13\n",
      "  enmap:defectivePixelsVNIR: 2\n",
      "  enmap:haze_cover: 1\n",
      "  enmap:imageID: 0000012252\n",
      "  enmap:instrumentStatusOK: true\n",
      "  enmap:missionPhase: routine\n",
      "  enmap:nodata: -32768\n",
      "  enmap:non_cloud_shadow: 0\n",
      "  enmap:numberOfTiles: 33\n",
      "  enmap:orbitNo: 12040\n",
      "  enmap:overallQuality: 0\n",
      "  enmap:overallQualitySWIR: 0\n",
      "  enmap:overallQualityVNIR: 0\n",
      "  enmap:ozoneValue: 330\n",
      "  enmap:phase: routine\n",
      "  enmap:processingDate: 2024-07-05T00:40:23.903890Z\n",
      "  enmap:productScreeningFailedGroups: NONE\n",
      "  enmap:productScreeningResultStatus: OK\n",
      "  enmap:qualityAtmosphere: 0\n",
      "  enmap:saturationCrosstalkSWIR: 0\n",
      "  enmap:saturationCrosstalkVNIR: 0\n",
      "  enmap:sceneAOT: 150\n",
      "  enmap:sceneAtmospericParameters: 0\n",
      "  enmap:sceneAzimuthAngle: 15.0063027624\n",
      "  enmap:sceneSunglint: 0\n",
      "  enmap:sceneTerrain: 0\n",
      "  enmap:sceneWV: 2284\n",
      "  enmap:season: summer\n",
      "  enmap:status: NOMINAL\n",
      "  enmap:statusSWIR: on\n",
      "  enmap:statusVNIR: on\n",
      "  enmap:sunAzimuthAngle: 168.49245\n",
      "  enmap:sunElevationAngle: 62.246176\n",
      "  enmap:swirNumberChannelsMissing: 0\n",
      "  enmap:tileID: 18\n",
      "  enmap:vnirNumberChannelsMissing: 0\n",
      "  enmap:water_cover: 2\n",
      "  eo:instrument: HSI\n",
      "  sci:citation: DLR (2024): EnMAP L0 Product 0000079715_18_L0_20240626T190122_010402_240705 doi: 10.15489/rlyibn8gjc58 Processed to level 2A (parameters: U0BLNNTS330G)\n",
      "\n",
      "Available assets in first item:\n",
      "- metadata\n",
      "- image\n",
      "- vnir\n",
      "- thumbnail\n",
      "- swir\n",
      "- quality_classes\n",
      "- quality_cloud\n",
      "- quality_cloud_shadow\n",
      "- quality_haze\n",
      "- quality_cirrus\n",
      "- quality_snow\n",
      "- quality_testflags\n",
      "- defective_pixel_mask\n",
      "\n",
      "\n",
      "Downloading image: ENMAP01-____L2A-DT0000079715_20240626T111139Z_018_V010402_20240705T004023Z-SPECTRAL_IMAGE_COG.TIF\n",
      "Progress: [==================================================] 452211030/452211030 bytes\n",
      "Successfully downloaded: EnMAP_downloads/L2A/ENMAP01-____L2A-DT0000079715_20240626T111139Z_018_V010402_20240705T004023Z-SPECTRAL_IMAGE_COG.TIF\n",
      "\n",
      "Processing item 2/2\n",
      "Cloud cover: 0%\n",
      "Item properties:\n",
      "  version: 01.04.02\n",
      "  created: 2024-04-12T23:22:48.217+00:00\n",
      "  updated: 2024-04-12T23:22:48.217+00:00\n",
      "  datetime: 2024-04-06T11:11:05.924619Z\n",
      "  start_datetime: 2024-04-06T11:11:03.657271Z\n",
      "  end_datetime: 2024-04-06T11:11:08.191968Z\n",
      "  platform: enmap\n",
      "  proj:epsg: None\n",
      "  sat:relative_orbit: 10846\n",
      "  eo:cloud_cover: 0\n",
      "  eo:snow_cover: 0\n",
      "  view:sun_azimuth: 351.726711\n",
      "  view:sun_elevation: 45.792474\n",
      "  processing:facility: NZ\n",
      "  processing:level: L2A\n",
      "  eop:sensorType: OPTICAL\n",
      "  card4l:eastern_geometric_accuracy: 5.0\n",
      "  card4l:geometric_accuracy_radial_rmse: 8.0\n",
      "  card4l:northern_geometric_accuracy: 5.0\n",
      "  card4l:specification: SR\n",
      "  card4l:specification_version: 5.0\n",
      "  enmap:SWIRAorSWIRBSelected: SWIRA\n",
      "  enmap:acquisitionConfiguration: earth\n",
      "  enmap:acquisitionType: EARTH\n",
      "  enmap:acrossOffNadirAngle: 0.118652798865\n",
      "  enmap:alongOffNadirAngle: -0.200498802183\n",
      "  enmap:archivedVersion: 01.04.02\n",
      "  enmap:biomeType: Temperate Broadleaf and Mixed Forests\n",
      "  enmap:cirrus_cover: 27\n",
      "  enmap:cloud_shadow: 0\n",
      "  enmap:compressionType: COMPRESSED\n",
      "  enmap:datatakeID: 0000068250\n",
      "  enmap:defectivePixelsSWIR: 12\n",
      "  enmap:defectivePixelsVNIR: 2\n",
      "  enmap:haze_cover: 3\n",
      "  enmap:imageID: 0000010621\n",
      "  enmap:instrumentStatusOK: true\n",
      "  enmap:missionPhase: routine\n",
      "  enmap:nodata: -32768\n",
      "  enmap:non_cloud_shadow: 0\n",
      "  enmap:numberOfTiles: 33\n",
      "  enmap:orbitNo: 10846\n",
      "  enmap:overallQuality: 1\n",
      "  enmap:overallQualitySWIR: 0\n",
      "  enmap:overallQualityVNIR: 0\n",
      "  enmap:ozoneValue: 330\n",
      "  enmap:phase: routine\n",
      "  enmap:processingDate: 2024-04-12T11:53:52.733740Z\n",
      "  enmap:productScreeningFailedGroups: NONE\n",
      "  enmap:productScreeningResultStatus: OK\n",
      "  enmap:qualityAtmosphere: 1\n",
      "  enmap:saturationCrosstalkSWIR: 0\n",
      "  enmap:saturationCrosstalkVNIR: 0\n",
      "  enmap:sceneAOT: 97\n",
      "  enmap:sceneAtmospericParameters: 0\n",
      "  enmap:sceneAzimuthAngle: 14.9955068766\n",
      "  enmap:sceneSunglint: 0\n",
      "  enmap:sceneTerrain: 0\n",
      "  enmap:sceneWV: 1067\n",
      "  enmap:season: summer\n",
      "  enmap:status: NOMINAL\n",
      "  enmap:statusSWIR: on\n",
      "  enmap:statusVNIR: on\n",
      "  enmap:sunAzimuthAngle: 171.726711\n",
      "  enmap:sunElevationAngle: 45.792474\n",
      "  enmap:swirNumberChannelsMissing: 0\n",
      "  enmap:tileID: 18\n",
      "  enmap:vnirNumberChannelsMissing: 0\n",
      "  enmap:water_cover: 1\n",
      "  eo:instrument: HSI\n",
      "\n",
      "Downloading image: ENMAP01-____L2A-DT0000068250_20240406T111103Z_018_V010402_20240412T115352Z-SPECTRAL_IMAGE_COG.TIF\n",
      "Progress: [==================================================] 436380644/436380644 bytes\n",
      "Successfully downloaded: EnMAP_downloads/L2A/ENMAP01-____L2A-DT0000068250_20240406T111103Z_018_V010402_20240412T115352Z-SPECTRAL_IMAGE_COG.TIF\n",
      "\n",
      "Download complete for ENMAP_HSI_L2A!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ******************************************************************************\n",
    "# EO-Lab Tutorial\n",
    "# Query and Download of EnMAP Data from the EOC Geoservice\n",
    "# ******************************************************************************\n",
    "#\n",
    "# This script demonstrates how to query and download EnMAP data from the EOC\n",
    "# Geoservice STAC catalogue. The code is organized into several sections:\n",
    "#   1. IMPORTS: Standard and third-party modules with explanations.\n",
    "#   2. USER CONFIGURATION: Parameters and settings you can adjust.\n",
    "#   3. HELPER FUNCTIONS: Utility functions for processing commands and geometry.\n",
    "#   4. ENMAPDOWNLOADER CLASS: Contains the logic for searching, filtering, and downloading.\n",
    "#   5. MAIN SCRIPT EXECUTION: Initiates the download process for enabled collections.\n",
    "#\n",
    "# Pre-requisites:\n",
    "#   - Python 3.x\n",
    "#   - Required libraries: os, re, requests, datetime, pystac_client, pathlib, math\n",
    "#   - A valid session (cookie) is required for downloading files.\n",
    "#\n",
    "# ******************************************************************************\n",
    "#\n",
    "# ------------------------------------------------------------------------------\n",
    "# Session Cookie Instructions:\n",
    "#\n",
    "# To download data from EOC Geoservice using curl, you must first obtain the session \n",
    "# cookie from the EOC Geoservice UMS. The easiest way is to log in to the \n",
    "# Geoservice EnMAP L2A Download page using your browser. When you log in \n",
    "# (choose \"External Identity Providers EO-LAB\" in the top right), open the Web \n",
    "# Developer Tools (e.g., press F12 in Firefox) and switch to the \"Network\" tab.\n",
    "#\n",
    "# Enter your credentials to log in. Look for a GET-request to \n",
    "# download.geoservice.dlr.de that contains the session cookie. Right-click that \n",
    "# request and select \"Copy\" -> \"Copy as cURL\". Use this copied cURL command in the \n",
    "# script (below) to download files.\n",
    "#\n",
    "# IMPORTANT:\n",
    "#   - The example cURL command provided here is only a template.\n",
    "#   - You must create your own cURL command with your session cookie.\n",
    "#   - Session cookies expire over time; for long downloads, repeat the procedure to \n",
    "#     obtain a new session cookie.\n",
    "#\n",
    "# To download additional files, simply replace the URL in the cURL command.\n",
    "# ------------------------------------------------------------------------------\n",
    "#\n",
    "# ---------------------------\n",
    "#           IMPORTS\n",
    "# ---------------------------\n",
    "import os              # For operating system interactions (file paths, directories)\n",
    "import re              # For regular expressions (pattern matching and extraction)\n",
    "import requests        # For making HTTP requests (downloading files)\n",
    "from datetime import datetime  # For date/time manipulation if needed\n",
    "from pystac_client import Client  # For accessing and querying the STAC catalogue\n",
    "from pathlib import Path  # For high-level file system path operations\n",
    "from math import cos, radians  # For geographic calculations (used to compute bounding boxes)\n",
    "\n",
    "# ---------------------------\n",
    "#      USER CONFIGURATION\n",
    "# ---------------------------\n",
    "\n",
    "# CURL command simulating a browser request; used to extract necessary HTTP headers.\n",
    "CURL_COMMAND = \"\"\"\n",
    "curl \"https://download.geoservice.dlr.de/ENMAP/files/L2A/?ticket=ST-11848-nWxfdPAbhjmUoQdgPeS8uTr-gps-auth\" -H \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0\" -H \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/png,image/svg+xml,*/*;q=0.8\" -H \"Accept-Language: de-DE,de;q=0.8,en-US;q=0.5,en;q=0.3\" -H \"Accept-Encoding: gzip, deflate, br, zstd\" -H \"DNT: 1\" -H \"Connection: keep-alive\" -H \"Cookie: session=Gpmbm3K-UAvKO0UmTO49OQ^|1739786884^|9zxCUa2Pz8OLhoe4zRQSYX515svNoPyKsLa93-7PevePOm7SkQBhBtKkWtOczQDe_v7f36KBsDIvQ9JIeJynkJntLlgpB3RKfsyqZV7fblipH2uMRJE3n4BDurIwMymM9KL4I8dEOruktKRpLCdgxyjurRXAQH80bK97bXq5Y2k^|cPfahrZ_q1kpCsKub_5j4QiiPlI\" -H \"Upgrade-Insecure-Requests: 1\" -H \"Sec-Fetch-Dest: document\" -H \"Sec-Fetch-Mode: navigate\" -H \"Sec-Fetch-Site: same-site\" -H \"Priority: u=0, i\" \"\"\"\n",
    "\n",
    "# Extract base URL from CURL_COMMAND (for potential modifications)\n",
    "CURL_PARTS = CURL_COMMAND.split(' ')\n",
    "BASE_URL = CURL_PARTS[1][1:-1]\n",
    "\n",
    "# Cloud cover filter: only process items with cloud cover below the specified maximum.\n",
    "CLOUD_COVER_FILTER = {\n",
    "    \"enabled\": True,         # Set to True to enable filtering.\n",
    "    \"max_coverage\": 5.0        # Maximum allowed cloud cover percentage.\n",
    "}\n",
    "\n",
    "# Flag to print all properties (metadata) for each item.\n",
    "PRINT_PROPERTIES = True\n",
    "\n",
    "# Define which collections to download and the asset types for each.\n",
    "DOWNLOADS = {\n",
    "    # L2A Collection (uses lowercase asset names)\n",
    "    \"ENMAP_HSI_L2A\": {\n",
    "        \"enabled\": True,  # Enable this collection for processing.\n",
    "        \"assets\": [\n",
    "            \"image\",  # Main spectral image.\n",
    "            # Uncomment additional asset types as needed:\n",
    "            # \"metadata\", \"vnir\", \"swir\", \"thumbnail\", etc.\n",
    "        ]\n",
    "    },\n",
    "    # L0 Quicklook Collection (uses UPPERCASE asset names)\n",
    "    \"ENMAP_HSI_L0_QL\": {\n",
    "        \"enabled\": False,  # Set to True to process this collection.\n",
    "        \"assets\": [\n",
    "            \"THUMBNAIL\",  # Quicklook thumbnail image.\n",
    "            \"OVERVIEW\",   # Quicklook overview image.\n",
    "            # Additional asset types can be added here.\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Area of interest configuration:\n",
    "# Option 1: Define a bounding box [west, south, east, north]\n",
    "BBOX = [11.230259, 48.051808, 11.337891, 48.117059]  # Example: DLR Oberpfaffenhofen\n",
    "\n",
    "# Option 2: Use a center coordinate with a specified box size (km)\n",
    "USE_CENTER_COORD = True  # Set to True to use center coordinate instead of a bounding box.\n",
    "CENTER_COORD = {\n",
    "    \"lat\": 50.71868778231684,  # Center latitude.\n",
    "    \"lon\": 7.158329088235492,  # Center longitude.\n",
    "    \"size_km\": 3              # Size of the square area in kilometers.\n",
    "}\n",
    "\n",
    "# Time range for the search (format: YYYY-MM-DD)\n",
    "START_DATE = \"2024-01-01\"  # Start date.\n",
    "END_DATE = \"2024-12-31\"    # End date.\n",
    "\n",
    "# Maximum number of items to process per collection (None means all found items)\n",
    "MAX_ITEMS = None\n",
    "\n",
    "# Download directory settings:\n",
    "CUSTOM_DOWNLOAD_PATH = None  # e.g., \"/home/user/my_enmap_data\" or \"C:/EnMAP_Data\"\n",
    "BASE_DIR = \"EnMAP_downloads\"  # Default directory if no custom path is provided.\n",
    "\n",
    "# ---------------------------\n",
    "#     HELPER FUNCTIONS\n",
    "# ---------------------------\n",
    "def clean_curl_command(curl_command):\n",
    "    # -----------------------------------------------------------\n",
    "    # Clean and format the provided CURL command.\n",
    "    # - Removes extra newlines and spaces.\n",
    "    # - Fixes cookie formatting (replaces '^|' with '|').\n",
    "    # - Ensures the command is properly quoted.\n",
    "    # -----------------------------------------------------------\n",
    "    curl_command = ' '.join(curl_command.split())  # Remove extra whitespace.\n",
    "    if 'Cookie:' in curl_command:\n",
    "        cookie_start = curl_command.find('Cookie:')\n",
    "        cookie_end = curl_command.find('\" -H', cookie_start)\n",
    "        if cookie_end == -1:\n",
    "            cookie_end = curl_command.find('\"', cookie_start + 15)\n",
    "        cookie_part = curl_command[cookie_start:cookie_end]\n",
    "        cleaned_cookie = cookie_part.replace('^|', '|')\n",
    "        curl_command = curl_command[:cookie_start] + cleaned_cookie + curl_command[cookie_end:]\n",
    "    if not curl_command.startswith('\"\"\"'):\n",
    "        curl_command = '\"\"\"' + curl_command + '\"\"\"'\n",
    "    return curl_command\n",
    "\n",
    "def parse_curl_command(curl_command):\n",
    "    # -----------------------------------------------------------\n",
    "    # Extract headers from the provided CURL command.\n",
    "    # Returns a dictionary mapping header names to their values.\n",
    "    # -----------------------------------------------------------\n",
    "    curl_command = clean_curl_command(curl_command)\n",
    "    headers = {}\n",
    "    header_pattern = r'-H\\s*\"([^:]+):\\s*([^\"]+)\"'\n",
    "    matches = re.findall(header_pattern, curl_command)\n",
    "    for header, value in matches:\n",
    "        headers[header] = value\n",
    "    return headers\n",
    "\n",
    "def create_bbox_from_center(lat, lon, size_km):\n",
    "    # -----------------------------------------------------------\n",
    "    # Create a bounding box from a center coordinate and box size.\n",
    "    #\n",
    "    # Parameters:\n",
    "    #   lat     - Center latitude.\n",
    "    #   lon     - Center longitude.\n",
    "    #   size_km - Size of the box in kilometers.\n",
    "    #\n",
    "    # Returns:\n",
    "    #   A list [west, south, east, north] representing the bounding box.\n",
    "    # -----------------------------------------------------------\n",
    "    km_per_degree_lat = 111.0  # Approximate kilometers per degree latitude.\n",
    "    km_per_degree_lon = 111.0 * cos(radians(lat))  # Adjusted for the given latitude.\n",
    "    lat_offset = (size_km / 2) / km_per_degree_lat\n",
    "    lon_offset = (size_km / 2) / km_per_degree_lon\n",
    "    west = lon - lon_offset\n",
    "    east = lon + lon_offset\n",
    "    south = lat - lat_offset\n",
    "    north = lat + lat_offset\n",
    "    return [west, south, east, north]\n",
    "\n",
    "# ---------------------------\n",
    "#    ENMAPDOWNLOADER CLASS\n",
    "# ---------------------------\n",
    "class EnmapDownloader:\n",
    "    # -----------------------------------------------------------\n",
    "    # Class to search, filter, and download EnMAP data items.\n",
    "    #\n",
    "    # Utilizes the STAC catalogue to locate items, applies filters\n",
    "    # (e.g., cloud cover), downloads specified assets, and optionally\n",
    "    # prints all item properties (metadata).\n",
    "    # -----------------------------------------------------------\n",
    "    def __init__(self):\n",
    "        self.catalog = Client.open(\"https://geoservice.dlr.de/eoc/ogc/stac/v1/\")\n",
    "        self.headers = parse_curl_command(CURL_COMMAND)\n",
    "        \n",
    "    def setup_download_directory(self, collection_name):\n",
    "        # -----------------------------------------------------------\n",
    "        # Create the download directory if it does not exist.\n",
    "        #\n",
    "        # Parameters:\n",
    "        #   collection_name - The folder name for the collection.\n",
    "        #\n",
    "        # Returns:\n",
    "        #   Full path to the download directory.\n",
    "        # -----------------------------------------------------------\n",
    "        if CUSTOM_DOWNLOAD_PATH:\n",
    "            base_path = os.path.expanduser(CUSTOM_DOWNLOAD_PATH)\n",
    "            target_directory = os.path.join(base_path, collection_name)\n",
    "        else:\n",
    "            target_directory = os.path.join(BASE_DIR, collection_name)\n",
    "        try:\n",
    "            if not os.path.exists(target_directory):\n",
    "                os.makedirs(target_directory)\n",
    "                print(f\"\\nCreated directory at: {target_directory}\")\n",
    "            else:\n",
    "                print(f\"\\nUsing existing directory at: {target_directory}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating directory: {str(e)}\")\n",
    "            print(\"Falling back to default directory\")\n",
    "            target_directory = os.path.join(BASE_DIR, collection_name)\n",
    "            if not os.path.exists(target_directory):\n",
    "                os.makedirs(target_directory)\n",
    "        return target_directory\n",
    "\n",
    "    def download_file(self, url, output_path):\n",
    "        # -----------------------------------------------------------\n",
    "        # Download a single file from the specified URL.\n",
    "        #\n",
    "        # Parameters:\n",
    "        #   url         - URL of the file to download.\n",
    "        #   output_path - Local path to save the downloaded file.\n",
    "        #\n",
    "        # Returns:\n",
    "        #   True if the download is successful, False otherwise.\n",
    "        # -----------------------------------------------------------\n",
    "        if 'Referer' in self.headers:\n",
    "            self.headers['Referer'] = os.path.dirname(url) + '/'\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, stream=True, allow_redirects=True)\n",
    "            response.raise_for_status()\n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "            with open(output_path, 'wb') as f:\n",
    "                if total_size == 0:\n",
    "                    f.write(response.content)\n",
    "                else:\n",
    "                    downloaded = 0\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                            downloaded += len(chunk)\n",
    "                            progress = int(50 * downloaded / total_size)\n",
    "                            print(f\"\\rProgress: [{'=' * progress}{' ' * (50 - progress)}] {downloaded}/{total_size} bytes\", end='')\n",
    "            print(f\"\\nSuccessfully downloaded: {output_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading file: {str(e)}\")\n",
    "            if os.path.exists(output_path):\n",
    "                os.remove(output_path)\n",
    "            return False\n",
    "\n",
    "    def search_and_download_collection(self, collection, asset_types):\n",
    "        # -----------------------------------------------------------\n",
    "        # Search for items in the specified collection, apply filters,\n",
    "        # and download the defined asset types.\n",
    "        #\n",
    "        # If PRINT_PROPERTIES is True, prints all properties for each item.\n",
    "        #\n",
    "        # Parameters:\n",
    "        #   collection  - Name of the collection.\n",
    "        #   asset_types - List of asset types (keys) to download from each item.\n",
    "        # -----------------------------------------------------------\n",
    "        print(f\"\\nSearching for {collection} data...\")\n",
    "        search_params = {\n",
    "            \"collections\": [collection],\n",
    "            \"bbox\": create_bbox_from_center(CENTER_COORD[\"lat\"],\n",
    "                                              CENTER_COORD[\"lon\"],\n",
    "                                              CENTER_COORD[\"size_km\"]) if USE_CENTER_COORD else BBOX\n",
    "        }\n",
    "        if START_DATE and END_DATE:\n",
    "            search_params[\"datetime\"] = f\"{START_DATE}T00:00:00Z/{END_DATE}T23:59:59Z\"\n",
    "        try:\n",
    "            search = self.catalog.search(**search_params)\n",
    "            total_matches = search.matched()\n",
    "            if total_matches == 0:\n",
    "                print(\"No items found matching your criteria.\")\n",
    "                return\n",
    "            print(f\"Found {total_matches} items.\")\n",
    "            items = list(search.items())\n",
    "            if CLOUD_COVER_FILTER[\"enabled\"]:\n",
    "                filtered_items = []\n",
    "                print(\"\\nFiltering by cloud cover...\")\n",
    "                for item in items:\n",
    "                    cloud_cover = float(item.properties.get(\"eo:cloud_cover\", 100.0))\n",
    "                    if cloud_cover <= CLOUD_COVER_FILTER[\"max_coverage\"]:\n",
    "                        filtered_items.append(item)\n",
    "                items = filtered_items\n",
    "                print(f\"After cloud cover filtering ({CLOUD_COVER_FILTER['max_coverage']}% max): {len(items)} items\")\n",
    "            items_to_process = min(MAX_ITEMS, len(items)) if MAX_ITEMS else len(items)\n",
    "            print(f\"Will download {items_to_process} items.\")\n",
    "            download_dir = self.setup_download_directory(collection.split('_')[-1])\n",
    "            items_processed = 0\n",
    "            for item in items:\n",
    "                if MAX_ITEMS and items_processed >= MAX_ITEMS:\n",
    "                    break\n",
    "                print(f\"\\nProcessing item {items_processed + 1}/{items_to_process}\")\n",
    "                print(f\"Cloud cover: {item.properties.get('eo:cloud_cover', 'N/A')}%\")\n",
    "                if PRINT_PROPERTIES:\n",
    "                    print(\"Item properties:\")\n",
    "                    for key, value in item.properties.items():\n",
    "                        print(f\"  {key}: {value}\")\n",
    "                assets = item.get_assets()\n",
    "                if items_processed == 0:\n",
    "                    print(\"\\nAvailable assets in first item:\")\n",
    "                    for asset_name in assets.keys():\n",
    "                        print(f\"- {asset_name}\")\n",
    "                    print()\n",
    "                for asset_type in asset_types:\n",
    "                    if asset_type in assets:\n",
    "                        asset = assets[asset_type]\n",
    "                        filename = os.path.basename(asset.href)\n",
    "                        output_path = os.path.join(download_dir, filename)\n",
    "                        print(f\"\\nDownloading {asset_type}: {filename}\")\n",
    "                        self.download_file(asset.href, output_path)\n",
    "                    else:\n",
    "                        print(f\"\\nAsset type {asset_type} not found in item\")\n",
    "                items_processed += 1\n",
    "            print(f\"\\nDownload complete for {collection}!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during search and download: {str(e)}\")\n",
    "\n",
    "    def download_all(self):\n",
    "        # -----------------------------------------------------------\n",
    "        # Iterate over all defined collections in DOWNLOADS.\n",
    "        # For each enabled collection, process and download the specified assets.\n",
    "        # -----------------------------------------------------------\n",
    "        for collection, config in DOWNLOADS.items():\n",
    "            if config[\"enabled\"]:\n",
    "                print(f\"\\n{'=' * 50}\")\n",
    "                print(f\"Processing collection: {collection}\")\n",
    "                print(f\"{'=' * 50}\")\n",
    "                self.search_and_download_collection(collection, config[\"assets\"])\n",
    "\n",
    "# ---------------------------\n",
    "#      MAIN SCRIPT EXECUTION\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    downloader = EnmapDownloader()\n",
    "    downloader.download_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfc323-ae80-4f06-afcb-35cfe5356af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geo science",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
